<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Henry Hyunkyu Lee</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <!-- and it's easy to individually load additional languages -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
<body>
    <header>
        <h1>Henry Lee (이현규)</h1>
        <nav>
            <ul>
                <li>
                    <a href="../index.html">Curriculum Vitae</a>
                </li>
                <li>
                    <a href="list.html">Computer Vision</a>
                </li>
                <li>
                    <a href="../til.html">TIL</a>
                </li>
            </ul>
        </nav>
        <hr>
    </header>
    <main>
        <article>
            <table style="width: 100%;">
                <thead>
                    <h2>You Only Look Once: Unified, Real-Time Object Detection</h2>
                    <p>2015</p>
                    <p>
                        Joseph Redmon∗, Santosh Divvala∗†, Ross Girshick¶, Ali Farhadi∗†<br>
                        University of Washington∗, Allen Institute for AI†, Facebook AI Research¶
                    </p>
                </thead>
                <tbody>
                    <tr>
                        <td style="width: 30%;">
                            먼저, 라이브러리를 불러온다.
                        </td>
                        <td style="width: 70%;">
                            <pre>
                                <code>
import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

print(tf.__version__)
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
try:
    tf.config.experimental.set_memory_growth(gpus[0], True)
except RuntimeError as e:
    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다
    print(e)
                                </code>
                            </pre>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            텐서플로에서 제공하는 ImageNet 데이터셋으로 사전 훈련된(Pre-trained) VGG16을 불러온다.
                        </td>
                        <td>
                            <pre>
                                <code>
backbone = tf.keras.applications.vgg16.VGG16(
    include_top=False,
    weights='imagenet',
    input_shape=(448,448,3)
)
                                </code>
                            </pre>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            활성함수(activation function)로 마지막 레이어에서 Linear를 사용하고, 나머지 모든 레이어는 LeakyRelu를 사용한다.
                        </td>
                        <td>
                            <pre>
                                <code>
for layer in backbone.layers:
    layer.trainable = False
    try:
        layer.activation = tf.keras.layers.LeakyReLU(alpha=0.1)
    except:
        pass
                                </code>
                            </pre>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            드롭아웃(Dropout) 레이어는 비율을 0.5로 하여 첫 FC 레이어 뒤에 둔다.
                        </td>
                        <td>
                            <pre>
                                <code>
x = tf.keras.layers.Conv2D(
    filters=1024,
    kernel_size=3,
    padding='same',
    activation=tf.keras.layers.LeakyReLU(alpha=0.1),
)(backbone.output)
x = tf.keras.layers.Conv2D(
    filters=1024,
    kernel_size=3,
    strides=(2,2),
    padding='same',
    activation=tf.keras.layers.LeakyReLU(alpha=0.1),
)(x)

x = tf.keras.layers.Conv2D(
    filters=1024,
    kernel_size=3,
    padding='same',
    activation=tf.keras.layers.LeakyReLU(alpha=0.1),
)(x)
x = tf.keras.layers.Conv2D(
    filters=1024,
    kernel_size=3,
    padding='same',
    activation=tf.keras.layers.LeakyReLU(alpha=0.1),
)(x)

x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(
    4096,
    activation=tf.keras.layers.LeakyReLU(alpha=0.1),
)(x)
x = tf.keras.layers.Dropout(0.5)(x)

x = tf.keras.layers.Dense(
    1470,
    activation='sigmoid',
)(x)
x = tf.keras.layers.Reshape((7,7,30))(x)

yolo = tf.keras.Model(inputs=backbone.input, outputs=x, name='Yolo')
                                </code>
                            </pre>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            손실함수(loss function)
                        </td>
                        <td>
                            <pre>
                                <code>
h_grid, w_grid = 7, 7

def get_iou(box1, box2):
    h_offset, w_offset = np.indices((h_grid, w_grid))

    x1, y1, w1, h1 = tf.unstack(box1, num=4, axis=-1) 
    area_box1 = w1 * h1

    x1_global = (w_offset + x1) / w_grid
    y1_global = (h_offset + y1) / h_grid
    x1_min, y1_min = x1_global - w1/2, y1_global - h1/2
    x1_max, y1_max = x1_global + w1/2, y1_global + h1/2

    x2, y2, w2, h2 = tf.unstack(box2, num=4, axis=-1)
    area_box2 = w2 * h2

    x2_global = (w_offset + x2) / w_grid
    y2_global = (h_offset + y2) / h_grid
    x2_min, y2_min = x2_global - w2/2, y2_global - h2/2
    x2_max, y2_max = x2_global + w2/2, y2_global + h2/2

    x_i_min = tf.math.maximum(x1_min, x2_min)
    y_i_min = tf.math.maximum(y1_min, y2_min)
    x_i_max = tf.math.minimum(x1_max, x2_max)
    y_i_max = tf.math.minimum(y1_max, y2_max)

    w_i = x_i_max - x_i_min
    h_i = y_i_max - y_i_min
    w_i = tf.math.maximum(0., w_i)
    h_i = tf.math.maximum(0., h_i)
    area_i = w_i * h_i

    union = area_box1 + area_box2 - area_i + 1e-8
    return tf.expand_dims((area_i / union), axis=-1)

def loss_function(true, pred, coord=5.0, noobj=0.5):
    true_conf = true[..., :1]
    true_boxes = true[..., 1:5]
    true_classes = true[..., 5:]
    
    box1_conf = pred[..., :1]
    box1_boxes = pred[..., 1:5]
    box2_conf = pred[..., 5:6]
    box2_boxes = pred[..., 6:10]
    pred_classes = pred[..., 10:]

    # class, shape = (batch, 7, 7, 20)
    cls_loss = tf.math.square(pred_classes-true_classes)
    cls_loss = tf.where(
        tf.math.equal(true_conf, 1.0),
        cls_loss,
        0.0
    )
    cls_loss = tf.math.reduce_sum(cls_loss, axis=[1,2,3])

    # boxes, shape = (batch, 7, 7, 4)
    xy_loss = tf.math.square(
        box1_boxes[..., 0:2]-true_boxes[..., 0:2]
    )
    wh_loss = tf.math.square(
        tf.math.sqrt(box1_boxes[..., 2:4])-tf.math.sqrt(true_boxes[..., 2:4])
    ) # 작은 상자의 오차에 가중치를 더 두기 위해서 제곱근(square root)을 씌워 예측
    box1_loss = xy_loss + wh_loss
    box1_loss = tf.where(
        tf.math.equal(true_conf, 1.0),
        box1_loss,
        0.0
    )

    xy_loss = tf.math.square(
        box2_boxes[..., 0:2]-true_boxes[..., 0:2]
    )
    wh_loss = tf.math.square(
        tf.math.sqrt(box2_boxes[..., 2:4])-tf.math.sqrt(true_boxes[..., 2:4])
    )
    box2_loss = xy_loss + wh_loss
    box2_loss = tf.where(
        tf.math.equal(true_conf, 1.0),
        box2_loss,
        0.0
    )

    iou_box1 = get_iou(true_boxes, box1_boxes)
    iou_box2 = get_iou(true_boxes, box2_boxes)

    box1_loss = tf.where(
        tf.math.greater_equal(iou_box1, iou_box2), 
        box1_loss*coord, 
        0.
    )
    box2_loss = tf.where(
        tf.math.less(iou_box1, iou_box2), 
        box2_loss*coord, 
        0.
    )
    box_loss = box1_loss + box2_loss
    box_loss = tf.math.reduce_sum(box_loss, axis=[1,2,3])

    # confidence, shape = (batch, 7, 7, 1)
    box1_conf_loss = tf.math.square(box1_conf - true_conf*iou_box1)
    box1_conf_loss = tf.where(
        tf.math.greater_equal(iou_box1, iou_box2), 
        box1_conf_loss, 
        box1_conf_loss*noobj
    )

    box2_conf_loss = tf.math.square(box2_conf - true_conf*iou_box2)
    box2_conf_loss = tf.where(
        tf.math.less(iou_box1, iou_box2), 
        box2_conf_loss, 
        box2_conf_loss*noobj
    )

    conf_loss = box1_conf_loss + box2_conf_loss
    conf_loss = tf.math.reduce_sum(conf_loss, axis=[1,2,3])

    return tf.math.reduce_mean(cls_loss+box_loss+conf_loss)
                                </code>
                            </pre>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            학습하는 동안 배치 사이즈는 64, Optimizer의 모멘텀은 0.9, Decay는 0.0005로 한다.
                        </td>
                        <td>
                            <pre>
                                <code>
sgd = tf.keras.optimizers.legacy.SGD(
    learning_rate=1e-3,
    momentum=0.9,
    decay=5e-4
)

yolo.compile(
    sgd,
    loss_function,
)
                                </code>
                            </pre>
                        </td>
                    </tr>
                    
                </tbody>
            </table>
        </article>
    </main>
</body>
</html>